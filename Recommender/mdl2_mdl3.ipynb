{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import bs4\n",
    "import json\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data_from_mdl.json')\n",
    "df['duration'] = (df['duration']/1000).map(int)\n",
    "#ao salvar o DF data_from_mdl do arquivo mdl1, o coluna 'duration' que era timedelta64 virou int64\n",
    "#ex:   1:30 viratam 90000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(index=df.index)\n",
    "y = df['y'].copy()\n",
    "features['time_pub'] = (pd.to_datetime('2020-04-23') - df['date']) / np.timedelta64(1, 'D')\n",
    "\n",
    "features['views'] = df['views']\n",
    "features['views_for_day'] = round(features['views'] / features['time_pub'], 2)\n",
    "\n",
    "features['likes'] = df['likes']\n",
    "features['likes_for_day'] = round(features['likes'] / features['time_pub'], 2)\n",
    "\n",
    "features['dislikes'] = df['dislikes']\n",
    "features['dislikes_for_day'] = round(features['dislikes'] / features['time_pub'], 2)\n",
    "\n",
    "features = features.drop(['time_pub'], axis=1)\n",
    "\n",
    "features['subscribers'] = df['subscribers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duração dos videos em segundos\n",
    "features['duration_seconds'] = df['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>views_for_day</th>\n",
       "      <th>likes</th>\n",
       "      <th>likes_for_day</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>dislikes_for_day</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>duration_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175311</td>\n",
       "      <td>281.85</td>\n",
       "      <td>5131</td>\n",
       "      <td>8.25</td>\n",
       "      <td>65</td>\n",
       "      <td>0.10</td>\n",
       "      <td>173000</td>\n",
       "      <td>29758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34724</td>\n",
       "      <td>58.07</td>\n",
       "      <td>782</td>\n",
       "      <td>1.31</td>\n",
       "      <td>20</td>\n",
       "      <td>0.03</td>\n",
       "      <td>484000</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18021</td>\n",
       "      <td>462.08</td>\n",
       "      <td>680</td>\n",
       "      <td>17.44</td>\n",
       "      <td>8</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1620000</td>\n",
       "      <td>33776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4193</td>\n",
       "      <td>11.75</td>\n",
       "      <td>94</td>\n",
       "      <td>0.26</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2840</td>\n",
       "      <td>4513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103756</td>\n",
       "      <td>165.48</td>\n",
       "      <td>3167</td>\n",
       "      <td>5.05</td>\n",
       "      <td>155</td>\n",
       "      <td>0.25</td>\n",
       "      <td>702000</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    views  views_for_day  likes  likes_for_day  dislikes  dislikes_for_day  \\\n",
       "0  175311         281.85   5131           8.25        65              0.10   \n",
       "1   34724          58.07    782           1.31        20              0.03   \n",
       "2   18021         462.08    680          17.44         8              0.21   \n",
       "3    4193          11.75     94           0.26         3              0.01   \n",
       "4  103756         165.48   3167           5.05       155              0.25   \n",
       "\n",
       "   subscribers  duration_seconds  \n",
       "0       173000             29758  \n",
       "1       484000               584  \n",
       "2      1620000             33776  \n",
       "3         2840              4513  \n",
       "4       702000               501  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((293, 8), (228, 8), (293,), (228,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask = df['date'] < '2019-07-31'\n",
    "valid_mask = df['date'] >= '2019-07-31'\n",
    "\n",
    "xtrain, xvalid = features[train_mask], features[valid_mask]\n",
    "ytrain, yvalid = y[train_mask], y[valid_mask]\n",
    "xtrain.shape, xvalid.shape, ytrain.shape, yvalid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<293x217 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1813 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#transforma text features em uma matriz Bag of Words (bow)\n",
    "#https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "\n",
    "title_train = df[train_mask]['title']\n",
    "title_valid = df[valid_mask]['title']\n",
    "\n",
    "title_vect = TfidfVectorizer(min_df=2)\n",
    "#min_df, se int, é o num min de exemplos que uma palavra precisa aparecer pra ser considerada, \n",
    "#se float, é o percentual min\n",
    "\n",
    "title_bow_train = title_vect.fit_transform(title_train)\n",
    "title_bow_valid = title_vect.transform(title_valid) \n",
    "#só transform pois valid simula os dados que não vão ser conhecidos pelo modelo\n",
    "\n",
    "#TfidfVectorizer retorna sparse matrices (matriz que não salva os 0s na mémoria, economizando muito espaço)\n",
    "\n",
    "title_bow_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028514807882858085"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1813/(293*217) #num de elementos salvos na matriz (num diferentes de 0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, vstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hstack - [1, 2]  [3, 4] -> [1, 2, 3, 4]\n",
    "\n",
    "vstack - [1, 2]  [3, 4] -> [1, 2]\n",
    "                           [3, 4]\n",
    "\n",
    "\n",
    "numpy também tem hstack e vstack, mas as funções nele não são otimizadas para sparse matrices, levaria muito mais tempo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 225)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_wtitle = hstack([xtrain, title_bow_train])\n",
    "xvalid_wtitle = hstack([xvalid, title_bow_valid])\n",
    "xtrain_wtitle.shape #217 colunas dos title 2 de views e views_for_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Novo Model (mdl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "mdl= RandomForestClassifier(n_estimators=1000, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "mdl.fit(xtrain_wtitle, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mdl.predict_proba(xvalid_wtitle)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7931746031746032, 0.9674311926605504)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "average_precision_score(yvalid, p), roc_auc_score(yvalid, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>duration_code</th>\n",
       "      <th>y</th>\n",
       "      <th>link</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>date</th>\n",
       "      <th>thumbnailUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Learn Python Basics for Data Science from IBM</td>\n",
       "      <td>PT2M29S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=JC3urnvKanI.html</td>\n",
       "      <td>245 mil</td>\n",
       "      <td>9.332</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>Publicado em 4 de abr. de 2019</td>\n",
       "      <td>https://i.ytimg.com/vi/JC3urnvKanI/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>What is Machine Learning ? (Tamil)</td>\n",
       "      <td>PT19M20S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=jdNDhCq5s0M.html</td>\n",
       "      <td>495</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Publicado em 20 de abr. de 2020</td>\n",
       "      <td>https://i.ytimg.com/vi/jdNDhCq5s0M/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Интенсив Data Science. Подведение итогов</td>\n",
       "      <td>PT87M16S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=jDntIbdSCks.html</td>\n",
       "      <td>41,7 mil</td>\n",
       "      <td>1.705</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>Transmitido ao vivo em 18 de abr. de 2020</td>\n",
       "      <td>https://i.ytimg.com/vi/jDntIbdSCks/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Module 1: Introduction to Data Science for Soc...</td>\n",
       "      <td>PT52M19S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=jG6pdz4DQu8.html</td>\n",
       "      <td>305</td>\n",
       "      <td>4.257</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>Publicado em 3 de jan. de 2018</td>\n",
       "      <td>https://i.ytimg.com/vi/jG6pdz4DQu8/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Python Basics for Data Science - Functions</td>\n",
       "      <td>PT13M29S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=jG73BfTEfvs.html</td>\n",
       "      <td>245 mil</td>\n",
       "      <td>1.344</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Publicado em 4 de abr. de 2019</td>\n",
       "      <td>https://i.ytimg.com/vi/jG73BfTEfvs/maxresdefau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title duration_code   y  \\\n",
       "515      Learn Python Basics for Data Science from IBM       PT2M29S NaN   \n",
       "516                 What is Machine Learning ? (Tamil)      PT19M20S NaN   \n",
       "517           Интенсив Data Science. Подведение итогов      PT87M16S NaN   \n",
       "518  Module 1: Introduction to Data Science for Soc...      PT52M19S NaN   \n",
       "519         Python Basics for Data Science - Functions      PT13M29S NaN   \n",
       "\n",
       "                                                 link subscribers  views  \\\n",
       "515  https://www.youtube.com/watch?v=JC3urnvKanI.html     245 mil  9.332   \n",
       "516  https://www.youtube.com/watch?v=jdNDhCq5s0M.html         495     70   \n",
       "517  https://www.youtube.com/watch?v=jDntIbdSCks.html    41,7 mil  1.705   \n",
       "518  https://www.youtube.com/watch?v=jG6pdz4DQu8.html         305  4.257   \n",
       "519  https://www.youtube.com/watch?v=jG73BfTEfvs.html     245 mil  1.344   \n",
       "\n",
       "     likes  dislikes                                       date  \\\n",
       "515     74         1             Publicado em 4 de abr. de 2019   \n",
       "516      3         1            Publicado em 20 de abr. de 2020   \n",
       "517     29         2  Transmitido ao vivo em 18 de abr. de 2020   \n",
       "518     92         1             Publicado em 3 de jan. de 2018   \n",
       "519     10         1             Publicado em 4 de abr. de 2019   \n",
       "\n",
       "                                          thumbnailUrl  \n",
       "515  https://i.ytimg.com/vi/JC3urnvKanI/maxresdefau...  \n",
       "516  https://i.ytimg.com/vi/jdNDhCq5s0M/maxresdefau...  \n",
       "517  https://i.ytimg.com/vi/jDntIbdSCks/maxresdefau...  \n",
       "518  https://i.ytimg.com/vi/jG6pdz4DQu8/maxresdefau...  \n",
       "519  https://i.ytimg.com/vi/jG73BfTEfvs/maxresdefau...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('data_with_label.csv', index_col=0)\n",
    "df_unlabeled = all_data[all_data['y'].isnull()]\n",
    "df_unlabeled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Cleaning df_unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "date = df_unlabeled['date'].str.extract('(\\d+) de (\\w+)\\. de (\\d+)')\n",
    "\n",
    "date[0] = date[0].map(lambda x: '0'+x if len(x)<2 else x) #add a 0 in days between 1 and 9\n",
    "\n",
    "months_map = {'jan':'01',\n",
    "             'fev': '02',\n",
    "             'mar': '03',\n",
    "             'abr':'04',\n",
    "             'mai':'05',\n",
    "             'jun':'06',\n",
    "             'jul':'07',\n",
    "             'ago':'08',\n",
    "             'set':'09',\n",
    "             'out':'10',\n",
    "             'nov':'11',\n",
    "             'dez':'12',}\n",
    "date[1] = date[1].map(months_map) #convert the months for numbers\n",
    "\n",
    "date = date.apply(lambda x: '-'.join(x), axis=1) #merges columns, joining str with '-'\n",
    "\n",
    "df_unlabeled['date']= pd.to_datetime(date, format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "duration = df_unlabeled['duration_code'].str.extract('PT(\\d+)M(\\d+)')\n",
    "\n",
    "minute = duration[0].map(int)\n",
    "seconds = duration[1].map(int)\n",
    "\n",
    "df_unlabeled['duration_code'] = minute*60 + seconds\n",
    "\n",
    "df_unlabeled.columns = ['title', 'duration', 'y', 'link', 'subscribers', 'views', 'likes',\n",
    "       'dislikes', 'date', 'thumbnailUrl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "subscribers = df_unlabeled['subscribers'].str.replace(',','.')\n",
    "\n",
    "def convert_unity(num):\n",
    "    \n",
    "    if 'mil' in num:\n",
    "        num = num.split()[0]\n",
    "        return float(num)*10**3\n",
    "    \n",
    "    elif 'mi' in num:\n",
    "        num = num.split()[0]\n",
    "        return float(num)*10**6\n",
    "    \n",
    "    else:\n",
    "        return float(num)\n",
    "        \n",
    "subscribers = subscribers.map(convert_unity).astype(int)\n",
    "\n",
    "df_unlabeled['subscribers'] = subscribers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_unlabeled['views'] = df_unlabeled['views'].str.replace('.', '').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Criando xu (x das features do df unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_u = pd.DataFrame(index=df_unlabeled.index)\n",
    "\n",
    "features_u['time_pub'] = (pd.to_datetime('2020-04-23') - df_unlabeled['date']) / np.timedelta64(1, 'D')\n",
    "\n",
    "features_u['views'] = df_unlabeled['views']\n",
    "features_u['views_for_day'] = round(features_u['views'] / features_u['time_pub'], 2)\n",
    "\n",
    "features_u['likes'] = df_unlabeled['likes']\n",
    "features_u['likes_for_day'] = round(features_u['likes'] / features_u['time_pub'], 2)\n",
    "\n",
    "features_u['dislikes'] = df_unlabeled['dislikes']\n",
    "features_u['dislikes_for_day'] = round(features_u['dislikes'] / features_u['time_pub'], 2)\n",
    "\n",
    "features_u = features_u.drop(['time_pub'], axis=1)\n",
    "\n",
    "features_u['subscribers'] = df_unlabeled['subscribers']\n",
    "features_u['duration_seconds'] = df_unlabeled['duration']\n",
    "\n",
    "title_u = df_unlabeled['title']\n",
    "title_bow_u = title_vect.transform(title_u)\n",
    "xu_wtitle = hstack([features_u, title_bow_u])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Resultados do mdl no xu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "pu = mdl.predict_proba(xu_wtitle)[:,1]\n",
    "df_unlabeled['p'] = pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>duration</th>\n",
       "      <th>y</th>\n",
       "      <th>link</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>date</th>\n",
       "      <th>thumbnailUrl</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Learn Python Basics for Data Science from IBM</td>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=JC3urnvKanI.html</td>\n",
       "      <td>245000</td>\n",
       "      <td>9332</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>https://i.ytimg.com/vi/JC3urnvKanI/maxresdefau...</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  duration   y  \\\n",
       "515  Learn Python Basics for Data Science from IBM       149 NaN   \n",
       "\n",
       "                                                 link  subscribers  views  \\\n",
       "515  https://www.youtube.com/watch?v=JC3urnvKanI.html       245000   9332   \n",
       "\n",
       "     likes  dislikes       date  \\\n",
       "515     74         1 2019-04-04   \n",
       "\n",
       "                                          thumbnailUrl      p  \n",
       "515  https://i.ytimg.com/vi/JC3urnvKanI/maxresdefau...  0.004  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unlabeled.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Separando os exemplos que o modelo teve mais dificuldade (70) e aleatórios (30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_h = (df_unlabeled['p'] >= 0.067) & (df_unlabeled['p'] <= 0.99)\n",
    "mask_h.sum() #num de exemplos no intervalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "difficult = df_unlabeled[mask_h]\n",
    "random = df_unlabeled[~mask_h].sample(27, random_state=42) \n",
    "# ~ negação, inverte os Treu e False da serie, para separar os exemplos que não estão nos difficult\n",
    "#.sample(n) pega um amostra aleatoria de n exemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_label1 = pd.concat([difficult, random])\n",
    "active_label1.to_csv('active_label1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('active_label_wy.csv', index_col=0)\n",
    "df2['p'] = active_label1['p'].to_list()\n",
    "#nos converter o active_label1.csv para anotar os y, a coluna 'p' foi alterada\n",
    "df2['date'] = df2['date'].astype(np.datetime64)\n",
    "#e as culuna 'date' mudou de tipo para str\n",
    "df2['novo'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Novo Model (mdl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df, df2.drop('p', axis=1)])\n",
    "df3 = df3.fillna(0)\n",
    "#df3 tem os 621 exemplos com label\n",
    "#coluna 'novo' tem 1 para os 100 novos exemplos e 0 para os 521 antigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(index=df3.index)\n",
    "y = df3['y'].copy()\n",
    "features['time_pub'] = (pd.to_datetime('2020-04-23') - df3['date']) / np.timedelta64(1, 'D')\n",
    "\n",
    "features['views'] = df3['views']\n",
    "features['views_for_day'] = round(features['views'] / features['time_pub'], 2)\n",
    "\n",
    "features['likes'] = df3['likes']\n",
    "features['likes_for_day'] = round(features['likes'] / features['time_pub'], 2)\n",
    "\n",
    "features['dislikes'] = df3['dislikes']\n",
    "features['dislikes_for_day'] = round(features['dislikes'] / features['time_pub'], 2)\n",
    "\n",
    "features = features.drop(['time_pub'], axis=1)\n",
    "\n",
    "features['subscribers'] = df3['subscribers']\n",
    "\n",
    "features['duration_seconds'] = df3['duration']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Agora temos o df3, com os 521 exemplos inicias e os novos 100 exemplos, limpo e formatado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Aumentando a validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usando os mesmos dados de treino e mais dados para valid\n",
    "train_mask = (df3['date'] < '2019-07-31') & (df3['novo']==0)\n",
    "valid_mask = df3['date'] >= '2019-07-31' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid = features[train_mask], features[valid_mask]\n",
    "ytrain, yvalid = y[train_mask], y[valid_mask]\n",
    "\n",
    "title_train = df3[train_mask]['title']\n",
    "title_valid = df3[valid_mask]['title']\n",
    "\n",
    "title_vect = TfidfVectorizer(min_df=2)\n",
    "\n",
    "title_bow_train = title_vect.fit_transform(title_train)\n",
    "title_bow_valid = title_vect.transform(title_valid) \n",
    "\n",
    "xtrain_wtitle = hstack([xtrain, title_bow_train])\n",
    "xvalid_wtitle = hstack([xvalid, title_bow_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl= RandomForestClassifier(n_estimators=1000, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "mdl.fit(xtrain_wtitle, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6486506329927382, 0.9616246498599439)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = mdl.predict_proba(xvalid_wtitle)[:,1]\n",
    "average_precision_score(yvalid, p), roc_auc_score(yvalid, p)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "antes (0.7931746031746032, 0.9674311926605504) sem active learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Aumentando o treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usando os mesmos dados de treino e mais dados para valid\n",
    "train_mask = (df3['date'] < '2019-07-31') \n",
    "valid_mask = (df3['date'] >= '2019-07-31' ) & (df3['novo']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid = features[train_mask], features[valid_mask]\n",
    "ytrain, yvalid = y[train_mask], y[valid_mask]\n",
    "\n",
    "title_train = df3[train_mask]['title']\n",
    "title_valid = df3[valid_mask]['title']\n",
    "\n",
    "title_vect = TfidfVectorizer(min_df=2)\n",
    "\n",
    "title_bow_train = title_vect.fit_transform(title_train)\n",
    "title_bow_valid = title_vect.transform(title_valid) \n",
    "\n",
    "xtrain_wtitle = hstack([xtrain, title_bow_train])\n",
    "xvalid_wtitle = hstack([xvalid, title_bow_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl= RandomForestClassifier(n_estimators=1000, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "mdl.fit(xtrain_wtitle, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8378618113912232, 0.9880733944954129)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = mdl.predict_proba(xvalid_wtitle)[:,1]\n",
    "average_precision_score(yvalid, p), roc_auc_score(yvalid, p)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(0.7931746031746032, 0.9674311926605504) sem active learning \n",
    "(0.6486506329927382, 0.9616246498599439) com active learning valid+ \n",
    "(0.8378618113912232, 0.9880733944954129) com active learning train+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Aumentando treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = (df3['date'] < '2019-07-31') \n",
    "valid_mask = (df3['date'] >= '2019-07-31' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid = features[train_mask], features[valid_mask]\n",
    "ytrain, yvalid = y[train_mask], y[valid_mask]\n",
    "\n",
    "title_train = df3[train_mask]['title']\n",
    "title_valid = df3[valid_mask]['title']\n",
    "\n",
    "title_vect = TfidfVectorizer(min_df=2)\n",
    "\n",
    "title_bow_train = title_vect.fit_transform(title_train)\n",
    "title_bow_valid = title_vect.transform(title_valid) \n",
    "\n",
    "xtrain_wtitle = hstack([xtrain, title_bow_train])\n",
    "xvalid_wtitle = hstack([xvalid, title_bow_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl= RandomForestClassifier(n_estimators=1000, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "mdl.fit(xtrain_wtitle, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.801072325936417, 0.985434173669468)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = mdl.predict_proba(xvalid_wtitle)[:,1]\n",
    "average_precision_score(yvalid, p), roc_auc_score(yvalid, p)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(0.7931746031746032, 0.9674311926605504) sem active learning \n",
    "(0.6486506329927382, 0.9616246498599439) com active learning valid+ \n",
    "(0.8378618113912232, 0.9880733944954129) com active learning train+\n",
    "(0.801072325936417, 0.985434173669468) com train+ valid+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
